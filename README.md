# BDA_Assignment3_Kafka

Streaming Data Insights on Amazon Metadata
Project Overview

This project aims to extract insights from streaming data using frequent itemset analysis on Amazon metadata. The dataset contains various attributes such as product ID, title, features, description, price, and more. Through preprocessing, streaming pipeline setup, frequent itemset mining, and database integration, we aim to derive meaningful associations and patterns from the data.
Approach
Preprocessing

    Data Loading: Load the sampled Amazon dataset.
    Data Cleaning and Formatting: Clean the data to remove duplicates, handle missing values, and ensure uniform data format.
    Preprocessed Data Generation: Generate a new JSON file containing the preprocessed data.
    Bonus: Implement batch processing for real-time preprocessing.

Streaming Pipeline Setup

    Producer Application: Develop an application to stream preprocessed data in real-time.
    Consumer Applications: Create three consumer applications to subscribe to the producer's data stream.

Frequent Itemset Mining

    Apriori Algorithm: Implement Apriori algorithm in one consumer to identify frequent itemsets. Employ sliding window approach for streaming data.
    PCY Algorithm: Implement PCY algorithm in one consumer to discover frequent itemsets efficiently. Utilize approximation techniques for streaming data.
    Innovative Analysis: Implement a creative analysis in the third consumer, exploring unique insights using streaming data techniques.

Database Integration

    Utilize MongoDB for database integration.
    Modify each consumer to connect to MongoDB and store the results.

Bash Script

    Develop a bash script to automate the execution of producer, consumers, and Kafka components initialization.

Repository Structure

    data: Contains the sampled Amazon dataset and preprocessed data files.
    src: Includes source code for preprocessing, streaming pipeline setup, frequent itemset mining, and database integration.
    scripts: Contains the bash script for project execution.
    README.md: Detailed documentation providing an overview, approach, instructions for execution, and insights derived from the project.

Execution Instructions

    Data Preparation: Download and sample the Amazon metadata dataset.
    Preprocessing: Execute the preprocessing script to clean and format the data.
    Streaming Setup: Run the producer application and three consumer applications.
    Frequent Itemset Mining: Monitor insights and associations generated by Apriori and PCY algorithms in real-time.
    Database Integration: Check MongoDB to access stored results.
    Bash Script: Optionally, execute the bash script for streamlined project execution.

Insights and Results

    Apriori and PCY algorithms successfully mine frequent itemsets from streaming data.
    MongoDB integration facilitates storage and retrieval of mined associations.
    Real-time insights provide valuable information for market analysis, recommendation systems, and more.

Conclusion

This project demonstrates the application of streaming data techniques, frequent itemset mining algorithms, and database integration on Amazon metadata. By leveraging innovative approaches and optimization techniques, we extract meaningful insights from large-scale streaming data, paving the way for advanced analytics and decision-making processes.
